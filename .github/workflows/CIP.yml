name: Customer Intelligence Pipeline

on:
  push:
    branches: [ "customer-Intelligence-pipeline" ]
  workflow_dispatch:

jobs:
  run-pipeline:
    runs-on: ubuntu-latest

    steps:
      - name: â¬‡ï¸ Checkout repository
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: ğŸš€ Run segmentation pipeline
        run: |
          python src/customer_segmentation_master.py

      - name: ğŸ§¹ Remove large model files before commit
        run: |
          echo "ğŸ§¹ Cleaning .pkl model artifacts..."
          find outputs -type f -name "*.pkl" -delete
          echo "âœ… Removed .pkl files from outputs to avoid GitHub size limit"

      - name: ğŸ•“ Get current timestamp
        id: datetime
        run: echo "timestamp=$(date +'%Y%m%d_%H%M')" >> $GITHUB_OUTPUT

      - name: ğŸ—ƒï¸ Commit & push generated outputs (PNG, CSV, XLSX only)
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@github.com"
          mkdir -p outputs/archive_${{ steps.datetime.outputs.timestamp }}
          
          # Move all new output files (except .pkl) into an archive folder
          find outputs -maxdepth 1 -type f ! -name "*.pkl" -exec mv {} outputs/archive_${{ steps.datetime.outputs.timestamp }}/ \;
          cp -r outputs/distributions outputs/archive_${{ steps.datetime.outputs.timestamp }}/distributions || true
          cp -r outputs/segments outputs/archive_${{ steps.datetime.outputs.timestamp }}/segments || true

          cd outputs
          git add archive_${{ steps.datetime.outputs.timestamp }}/
          git commit -m "ğŸ“¦ Add generated outputs (no model binaries) from workflow run"
          git push origin customer-Intelligence-pipeline
